{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb0ad3f-b0f0-4768-b74e-40d4f5c7cac4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import json\n",
    "with open('./stage_5.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "# base_url = \"https://digitalwires.dpa-newslab.com/iaeystP2ZVzUx1PBhd5Tr2LODbdSavCV/aufschaltung/au-clC0AH31tVaf0fbHu2/apigate-electionsdata/f-wmGZTrfmonUjD1FR\"\n",
    "# us_election_id = \"us-2024\"\n",
    "# results = \"results?election=us-2024&stage=sim\"\n",
    "\n",
    "# url = f\"{base_url}/{results}\"\n",
    "\n",
    "\n",
    "# response = requests.get(url)\n",
    "\n",
    "# if response.status_code == 200:\n",
    "#     data = response.json()\n",
    "#     print(\"Successfully received data\")\n",
    "# else:\n",
    "#     print(f\"Request failed with status code: {response.status_code}\")\n",
    "#     print(f\"Response content: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fefae201-f556-4a04-b8a5-5ee93d36101d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello of rows in df_constituencies: 51\n"
     ]
    }
   ],
   "source": [
    "results_per_constituency = data['election']['contest'][0]['results_per_constituency']\n",
    "constituencies_data = data['constituencies']\n",
    "\n",
    "# Create a dictionary to map constituency_id to name\n",
    "constituency_id_to_name = {}\n",
    "for constituency in constituencies_data:\n",
    "    constituency_id = constituency['id']\n",
    "    constituency_id_to_name[constituency_id] = constituency['name']\n",
    "\n",
    "# Create lists to store the data for our DataFrame\n",
    "ids = []\n",
    "names = []\n",
    "\n",
    "# Iterate through results_per_constituency\n",
    "for result in results_per_constituency:\n",
    "    constituency_id = result['constituency_id']\n",
    "    ids.append(constituency_id)\n",
    "    \n",
    "    # Get the name from our mapping, or use 'Unknown' if not found\n",
    "    name = constituency_id_to_name.get(constituency_id, 'Unknown')\n",
    "    names.append(name)\n",
    "\n",
    "# Create the DataFrame\n",
    "constituencies_df = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'name': names\n",
    "})\n",
    "\n",
    "# Verify the length of the DataFrame\n",
    "print(f\"Hello of rows in df_constituencies: {len(constituencies_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ff855ae-219c-4de2-93f0-748d043b3f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status_date': '2024-10-24T12:37:00.000Z',\n",
       " 'type': 'trend',\n",
       " 'source': {'name': 'CNN'},\n",
       " 'additional_information': {'turnout': None,\n",
       "  'turnout_predicted': None,\n",
       "  'voters': None,\n",
       "  'votes': [],\n",
       "  'votes_valid': [],\n",
       "  'votes_invalid': []},\n",
       " 'results': [{'target': 'candidates',\n",
       "   'target_id': '229df5e1-8bca-415d-b70e-74bd44148d98',\n",
       "   'percent': [],\n",
       "   'votes': [],\n",
       "   'seats': {}},\n",
       "  {'target': 'candidates',\n",
       "   'target_id': 'e49b06b7-da26-4d59-ad36-166c9eddfffb',\n",
       "   'percent': [],\n",
       "   'votes': [],\n",
       "   'seats': {}}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search = data['election']['contest'][0]['results_per_constituency']\n",
    "\n",
    "# matched_result = None\n",
    "# for result in search:\n",
    "#     constituency_id = result['constituency_id']\n",
    "#     state_name = constituencies_df.loc[constituencies_df['id'] == constituency_id, 'name'].iloc[0]\n",
    "    \n",
    "#     if state_name.lower() == 'kentucky':\n",
    "#         matched_result = result\n",
    "#         break\n",
    "# else:\n",
    "#     print(\"not found in the results.\")\n",
    "\n",
    "# matched_result['latest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc24326f-34d9-403b-9fc1-fbb4e7e197f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c8/bvk5bjs15mzg5h8m_jcbywx40000gn/T/ipykernel_4000/3228986458.py:76: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results = data['election']['contest'][0]['results_per_constituency']\n",
    "results_df = pd.DataFrame(columns=['state', 'trump_score', 'harris_score', 'position', 'seats_republican', 'seats_democrat', 'type'])\n",
    "for result in results:\n",
    "    constituency_id = result['constituency_id']\n",
    "    state_name = constituencies_df.loc[constituencies_df['id'] == constituency_id, 'name'].iloc[0]\n",
    "    \n",
    "    # Initialize empty values\n",
    "    trump_score = ''\n",
    "    harris_score = ''\n",
    "    position = ''\n",
    "    seats_republican = ''\n",
    "    seats_democrat = ''\n",
    "    result_type = ''\n",
    "    \n",
    "    # Only process if there are latest results\n",
    "    if result['latest']:\n",
    "        result_type = result['latest']['type']\n",
    "        \n",
    "        for candidate_result in result['latest']['results']:\n",
    "            target_id = candidate_result['target_id']\n",
    "            \n",
    "            if candidate_result['percent']:\n",
    "                score = candidate_result['percent'][0]['value'].get('absolute', '')\n",
    "            else:\n",
    "                score = ''\n",
    "            \n",
    "            # Find the corresponding candidate\n",
    "            candidate = next((c for c in data['candidates'] if c['id'] == target_id), None)\n",
    "            if candidate:\n",
    "                person_id = candidate['person_id']\n",
    "                \n",
    "                # Find the corresponding person\n",
    "                person = next((p for p in data['persons'] if p['id'] == person_id), None)\n",
    "                if person:\n",
    "                    name = f\"{person['first_name']} {person['last_name']}\"\n",
    "                    if 'Donald Trump' in name:\n",
    "                        trump_score = score\n",
    "                        if candidate_result.get('seats'):\n",
    "                            seats_republican = candidate_result['seats'].get('absolute', '')\n",
    "                    elif 'Kamala Harris' in name:\n",
    "                        harris_score = score\n",
    "                        if candidate_result.get('seats'):\n",
    "                            seats_democrat = candidate_result['seats'].get('absolute', '')\n",
    "        \n",
    "        # Only calculate position if we have both scores and they're not empty\n",
    "        if trump_score != '' and harris_score != '':\n",
    "            # Check for split seats\n",
    "            if seats_republican and seats_democrat and float(seats_republican) > 0 and float(seats_democrat) > 0:\n",
    "                if result_type == 'trend':\n",
    "                    position = 'split_lean'\n",
    "                elif result_type == 'preliminary':\n",
    "                    position = 'split_called'\n",
    "            else:\n",
    "                score_difference = abs(harris_score - trump_score)\n",
    "                if result_type == 'trend':\n",
    "                    if score_difference < 6:\n",
    "                        position = 'battleground'\n",
    "                    elif harris_score > trump_score:\n",
    "                        position = 'lean_harris'\n",
    "                    else:\n",
    "                        position = 'lean_trump'\n",
    "                elif result_type == 'preliminary':\n",
    "                    position = 'democrat' if harris_score > trump_score else 'republican'\n",
    "    \n",
    "    # Add the data to results_df regardless of whether latest exists\n",
    "    new_row = pd.DataFrame({\n",
    "        'state': [state_name],\n",
    "        'trump_score': [trump_score],\n",
    "        'harris_score': [harris_score],\n",
    "        'position': [position],\n",
    "        'seats_republican': [seats_republican],\n",
    "        'seats_democrat': [seats_democrat],\n",
    "        'type': [result_type]\n",
    "    })\n",
    "    \n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "results_df.to_csv(\"dpa_map_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a849bf4-9b50-4075-a622-5802ed92002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "electoral_votes = {\n",
    "    'arizona': 11, 'california': 54, 'georgia': 16, 'florida': 30, 'maryland': 10,\n",
    "    'michigan': 15, 'minnesota': 10, 'missouri': 10, 'montana': 4, 'nevada': 6,\n",
    "    'new_mexico': 5, 'new_york': 28, 'north_carolina': 16, 'pennsylvania': 19,\n",
    "    'texas': 40, 'virginia': 13, 'wisconsin': 10,\n",
    "    'alabama': 9, 'alaska': 3, 'arkansas': 6, 'colorado': 10, 'connecticut': 7,\n",
    "    'delaware': 3, 'hawaii': 4, 'idaho': 4, 'illinois': 19, 'indiana': 11,\n",
    "    'iowa': 6, 'kansas': 6, 'kentucky': 8, 'louisiana': 8, 'maine': 4,\n",
    "    'massachusetts': 11, 'mississippi': 6, 'nebraska': 5, 'new_hampshire': 4,\n",
    "    'new_jersey': 14, 'north_dakota': 3, 'ohio': 17, 'oklahoma': 7, 'oregon': 8,\n",
    "    'rhode_island': 4, 'south_carolina': 9, 'south_dakota': 3, 'tennessee': 11,\n",
    "    'utah': 6, 'vermont': 3, 'washington': 12, 'washington_dc': 3, 'west_virginia': 4,\n",
    "    'wyoming': 3\n",
    "}\n",
    "\n",
    "# Initialize counters for all categories\n",
    "democrat_seats = 0\n",
    "republican_seats = 0\n",
    "lean_democrat_seats = 0\n",
    "lean_republican_seats = 0\n",
    "battleground_seats = 0\n",
    "\n",
    "# Process each state in results_df\n",
    "for _, row in results_df.iterrows():\n",
    "    state = row['state'].lower().replace(' ', '_')\n",
    "    position = row['position']\n",
    "    \n",
    "    # Get electoral votes for the state\n",
    "    state_electoral_votes = electoral_votes.get(state, 0)\n",
    "    \n",
    "    # Convert seats to float, handle empty strings\n",
    "    seats_dem = int(float(row['seats_democrat'])) if row['seats_democrat'] != '' else 0\n",
    "    seats_rep = int(float(row['seats_republican'])) if row['seats_republican'] != '' else 0\n",
    "    \n",
    "    # Determine if we need to use electoral votes (when both seat counts are 0)\n",
    "    use_electoral_votes = seats_dem == 0 and seats_rep == 0\n",
    "    \n",
    "    if position == 'democrat':\n",
    "        if use_electoral_votes:\n",
    "            democrat_seats += state_electoral_votes\n",
    "        else:\n",
    "            democrat_seats += seats_dem\n",
    "    \n",
    "    elif position == 'republican':\n",
    "        if use_electoral_votes:\n",
    "            republican_seats += state_electoral_votes\n",
    "        else:\n",
    "            republican_seats += seats_rep\n",
    "    \n",
    "    elif position == 'lean_harris':\n",
    "        if use_electoral_votes:\n",
    "            lean_democrat_seats += state_electoral_votes\n",
    "        else:\n",
    "            lean_democrat_seats += seats_dem\n",
    "    \n",
    "    elif position == 'lean_trump':\n",
    "        if use_electoral_votes:\n",
    "            lean_republican_seats += state_electoral_votes\n",
    "        else:\n",
    "            lean_republican_seats += seats_rep\n",
    "    \n",
    "    elif position == 'battleground':\n",
    "        battleground_seats += state_electoral_votes\n",
    "        \n",
    "    elif position == 'split_lean':\n",
    "        lean_democrat_seats += seats_dem\n",
    "        lean_republican_seats += seats_rep\n",
    "        \n",
    "    elif position == 'split_called':\n",
    "        democrat_seats += seats_dem\n",
    "        republican_seats += seats_rep\n",
    "\n",
    "# Create the widget DataFrame with explicit integer type\n",
    "widget_df = pd.DataFrame({\n",
    "    'democrat': [int(democrat_seats)],\n",
    "    'republican': [int(republican_seats)],\n",
    "    'lean_harris': [int(lean_democrat_seats)],\n",
    "    'lean_trump': [int(lean_republican_seats)],\n",
    "    'battleground': [int(battleground_seats)]\n",
    "})\n",
    "\n",
    "widget_df.to_csv(\"dpa_widget.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51c46963-66fa-45a2-a126-57fd8bdc341c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dpa_michigan.csv\n",
      "Updated dpa_wisconsin.csv\n",
      "Updated dpa_pennsylvania.csv\n",
      "Updated dpa_nevada.csv\n",
      "Updated dpa_arizona.csv\n",
      "Updated dpa_north_carolina.csv\n",
      "Updated dpa_georgia.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c8/bvk5bjs15mzg5h8m_jcbywx40000gn/T/ipykernel_888/2288087970.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n",
      "/var/folders/c8/bvk5bjs15mzg5h8m_jcbywx40000gn/T/ipykernel_888/2288087970.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n",
      "/var/folders/c8/bvk5bjs15mzg5h8m_jcbywx40000gn/T/ipykernel_888/2288087970.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n",
      "/var/folders/c8/bvk5bjs15mzg5h8m_jcbywx40000gn/T/ipykernel_888/2288087970.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n",
      "/var/folders/c8/bvk5bjs15mzg5h8m_jcbywx40000gn/T/ipykernel_888/2288087970.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n",
      "/var/folders/c8/bvk5bjs15mzg5h8m_jcbywx40000gn/T/ipykernel_888/2288087970.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n",
      "/var/folders/c8/bvk5bjs15mzg5h8m_jcbywx40000gn/T/ipykernel_888/2288087970.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "swing_states = ['michigan', 'wisconsin', 'pennsylvania', 'nevada', 'arizona', 'north_carolina', 'georgia']\n",
    "\n",
    "def update_state_data(state, results_row):\n",
    "    csv_name = f\"dpa_{state.lower().replace(' ', '_')}.csv\"\n",
    "    df = pd.read_csv(csv_name, parse_dates=['date'])\n",
    "    \n",
    "    # Convert scores to float for proper comparison\n",
    "    trump_score = float(results_row['trump_score']) if results_row['trump_score'] != '' else 0\n",
    "    harris_score = float(results_row['harris_score']) if results_row['harris_score'] != '' else 0\n",
    "    \n",
    "    new_row = pd.DataFrame({\n",
    "        'date': [datetime.now()],\n",
    "        'trump_score': [results_row['trump_score']],\n",
    "        'harris_score': [results_row['harris_score']],\n",
    "        'candidate_lead': ['harris' if harris_score > trump_score else 'trump' if trump_score > harris_score else ''],\n",
    "        'position': [results_row['position']]\n",
    "    })\n",
    "    \n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    df.to_csv(csv_name, index=False)\n",
    "    print(f\"Updated {csv_name}\")\n",
    "\n",
    "def normalize_state_name(name):\n",
    "    return name.lower().replace(' ', '_')\n",
    "\n",
    "def update_swing_state_data(results_df):\n",
    "    results_df['normalized_state'] = results_df['state'].apply(normalize_state_name)\n",
    "    \n",
    "    for state in swing_states:\n",
    "        csv_name = f\"dpa_{state.lower().replace(' ', '_')}.csv\"\n",
    "        \n",
    "        # Check the latest position in the current CSV\n",
    "        current_df = pd.read_csv(csv_name)\n",
    "        if not current_df.empty and current_df['position'].iloc[-1] in ['democrat', 'republican']:\n",
    "            print(f\"Skipping {state} as it's already decided ({current_df['position'].iloc[-1]})\")\n",
    "            continue\n",
    "        \n",
    "        # Find the corresponding row in results_df\n",
    "        state_data = results_df[results_df['normalized_state'] == normalize_state_name(state)]\n",
    "        \n",
    "        if not state_data.empty:\n",
    "            update_state_data(state, state_data.iloc[0])\n",
    "        else:\n",
    "            print(f\"No data found for {state} in results_df\")\n",
    "\n",
    "update_swing_state_data(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dea63af-5d3e-4f4a-985a-16d3943ae9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset and created empty CSV file: dpa_michigan.csv\n",
      "Reset and created empty CSV file: dpa_wisconsin.csv\n",
      "Reset and created empty CSV file: dpa_pennsylvania.csv\n",
      "Reset and created empty CSV file: dpa_nevada.csv\n",
      "Reset and created empty CSV file: dpa_arizona.csv\n",
      "Reset and created empty CSV file: dpa_north_carolina.csv\n",
      "Reset and created empty CSV file: dpa_georgia.csv\n"
     ]
    }
   ],
   "source": [
    "# erase and re-create all csvs\n",
    "# import os\n",
    "# columns = ['date', 'trump_score', 'harris_score', 'candidate_lead', 'position']\n",
    "\n",
    "# # Function to reset CSV files\n",
    "# def reset_csv_files():\n",
    "#     for state in swing_states:\n",
    "#         filename = f\"dpa_{state.lower().replace(' ', '_')}.csv\"\n",
    "#         # Remove existing file if it exists\n",
    "#         if os.path.exists(filename):\n",
    "#             os.remove(filename)\n",
    "#         # Create new empty CSV file\n",
    "#         df = pd.DataFrame(columns=columns)\n",
    "#         df.to_csv(filename, index=False)\n",
    "#         print(f\"Reset and created empty CSV file: {filename}\")\n",
    "\n",
    "# reset_csv_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d2b9a7-fcbe-43c0-b0d0-99b8cd4c989b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
