{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb0ad3f-b0f0-4768-b74e-40d4f5c7cac4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully received data\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# import json\n",
    "# with open('./stage_5.json', 'r') as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "# print(data)\n",
    "base_url = \"https://digitalwires.dpa-newslab.com/iaeystP2ZVzUx1PBhd5Tr2LODbdSavCV/aufschaltung/au-clC0AH31tVaf0fbHu2/apigate-electionsdata/f-wmGZTrfmonUjD1FR\"\n",
    "us_election_id = \"us-2024\"\n",
    "results = \"results?election=us-2024&stage=live\"\n",
    "\n",
    "url = f\"{base_url}/{results}\"\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(\"Successfully received data\")\n",
    "else:\n",
    "    print(f\"Request failed with status code: {response.status_code}\")\n",
    "    print(f\"Response content: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fefae201-f556-4a04-b8a5-5ee93d36101d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello of rows in df_constituencies: 51\n"
     ]
    }
   ],
   "source": [
    "results_per_constituency = data['election']['contest'][0]['results_per_constituency']\n",
    "constituencies_data = data['constituencies']\n",
    "\n",
    "# Create a dictionary to map constituency_id to name\n",
    "constituency_id_to_name = {}\n",
    "for constituency in constituencies_data:\n",
    "    constituency_id = constituency['id']\n",
    "    constituency_id_to_name[constituency_id] = constituency['name']\n",
    "\n",
    "# Create lists to store the data for our DataFrame\n",
    "ids = []\n",
    "names = []\n",
    "\n",
    "# Iterate through results_per_constituency\n",
    "for result in results_per_constituency:\n",
    "    constituency_id = result['constituency_id']\n",
    "    ids.append(constituency_id)\n",
    "    \n",
    "    # Get the name from our mapping, or use 'Unknown' if not found\n",
    "    name = constituency_id_to_name.get(constituency_id, 'Unknown')\n",
    "    names.append(name)\n",
    "\n",
    "# Create the DataFrame\n",
    "constituencies_df = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'name': names\n",
    "})\n",
    "\n",
    "# Verify the length of the DataFrame\n",
    "print(f\"Hello of rows in df_constituencies: {len(constituencies_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc24326f-34d9-403b-9fc1-fbb4e7e197f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "electoral_votes = {\n",
    "    'alabama': 9, 'alaska': 3, 'arizona': 11, 'arkansas': 6, 'california': 54,\n",
    "    'colorado': 10, 'connecticut': 7, 'delaware': 3, 'florida': 30, 'georgia': 16,\n",
    "    'hawaii': 4, 'idaho': 4, 'illinois': 19, 'indiana': 11, 'iowa': 6,\n",
    "    'kansas': 6, 'kentucky': 8, 'louisiana': 8, 'maine': 4, 'maryland': 10,\n",
    "    'massachusetts': 11, 'michigan': 15, 'minnesota': 10, 'mississippi': 6,\n",
    "    'missouri': 10, 'montana': 4, 'nebraska': 5, 'nevada': 6, 'new_hampshire': 4,\n",
    "    'new_jersey': 14, 'new_mexico': 5, 'new_york': 28, 'north_carolina': 16,\n",
    "    'north_dakota': 3, 'ohio': 17, 'oklahoma': 7, 'oregon': 8, 'pennsylvania': 19,\n",
    "    'rhode_island': 4, 'south_carolina': 9, 'south_dakota': 3, 'tennessee': 11,\n",
    "    'texas': 40, 'utah': 6, 'vermont': 3, 'virginia': 13, 'washington': 12,\n",
    "    'washington_dc': 3, 'west_virginia': 4, 'wisconsin': 10, 'wyoming': 3\n",
    "}\n",
    "\n",
    "# First create the map data\n",
    "results = data['election']['contest'][0]['results_per_constituency']\n",
    "results_df = pd.DataFrame(columns=['state', 'position', 'seats_republican', 'seats_democrat', 'type'])\n",
    "\n",
    "# Process each constituency\n",
    "for result in results:\n",
    "    constituency_id = result['constituency_id']\n",
    "    state_name = constituencies_df.loc[constituencies_df['id'] == constituency_id, 'name'].iloc[0]\n",
    "    \n",
    "    # Initialize empty values\n",
    "    position = 'battleground'  # Default position\n",
    "    seats_republican = ''\n",
    "    seats_democrat = ''\n",
    "    result_type = ''\n",
    "    \n",
    "    # Only process seats if there are preliminary results\n",
    "    if result['latest'] and result['latest']['type'] == 'preliminary':\n",
    "        result_type = 'preliminary'\n",
    "        \n",
    "        for candidate_result in result['latest']['results']:\n",
    "            target_id = candidate_result['target_id']\n",
    "            \n",
    "            # Find the corresponding candidate\n",
    "            candidate = next((c for c in data['candidates'] if c['id'] == target_id), None)\n",
    "            if candidate:\n",
    "                person_id = candidate['person_id']\n",
    "                person = next((p for p in data['persons'] if p['id'] == person_id), None)\n",
    "                \n",
    "                if person:\n",
    "                    name = f\"{person['first_name']} {person['last_name']}\"\n",
    "                    if 'Donald Trump' in name and candidate_result.get('seats'):\n",
    "                        seats_republican = candidate_result['seats'].get('absolute', '')\n",
    "                    elif 'Kamala Harris' in name and candidate_result.get('seats'):\n",
    "                        seats_democrat = candidate_result['seats'].get('absolute', '')\n",
    "        \n",
    "        # Check for split states first\n",
    "        if (seats_republican and seats_democrat and \n",
    "            float(seats_republican) > 0 and float(seats_democrat) > 0):\n",
    "            position = 'split_called'\n",
    "        # Then check for single winner states\n",
    "        elif seats_republican and float(seats_republican) > 0:\n",
    "            position = 'republican'\n",
    "        elif seats_democrat and float(seats_democrat) > 0:\n",
    "            position = 'democrat'\n",
    "    \n",
    "    new_row = pd.DataFrame({\n",
    "        'state': [state_name],\n",
    "        'position': [position],\n",
    "        'seats_republican': [seats_republican],\n",
    "        'seats_democrat': [seats_democrat],\n",
    "        'type': [result_type]\n",
    "    })\n",
    "    \n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "# Save map data\n",
    "results_df.to_csv(\"dpa_map_data.csv\", index=False)\n",
    "\n",
    "# Initialize counters for widget\n",
    "democrat_seats = 0\n",
    "republican_seats = 0\n",
    "battleground_seats = 0\n",
    "\n",
    "# Process each state for widget data\n",
    "for _, row in results_df.iterrows():\n",
    "    state = row['state'].lower().replace(' ', '_')\n",
    "    position = row['position'] if pd.notna(row['position']) else 'battleground'\n",
    "    \n",
    "    # Get electoral votes for this state\n",
    "    state_electoral_votes = electoral_votes.get(state, 0)\n",
    "    if state == 'district_of_columbia':  # Handle DC special case\n",
    "        state_electoral_votes = electoral_votes['washington_dc']\n",
    "    \n",
    "    # Convert seats to numbers, handling empty strings and NaN\n",
    "    seats_dem = int(float(row['seats_democrat'])) if pd.notna(row['seats_democrat']) and row['seats_democrat'] != '' else 0\n",
    "    seats_rep = int(float(row['seats_republican'])) if pd.notna(row['seats_republican']) and row['seats_republican'] != '' else 0\n",
    "    \n",
    "    print(f\"\\nProcessing {state}\")\n",
    "    print(f\"Position: {position}\")\n",
    "    print(f\"Electoral votes: {state_electoral_votes}\")\n",
    "    print(f\"Democrat seats: {seats_dem}, Republican seats: {seats_rep}\")\n",
    "    \n",
    "    if position == 'democrat':\n",
    "        if seats_dem > 0:\n",
    "            democrat_seats += seats_dem\n",
    "        else:\n",
    "            democrat_seats += state_electoral_votes\n",
    "            \n",
    "    elif position == 'republican':\n",
    "        if seats_rep > 0:\n",
    "            republican_seats += seats_rep\n",
    "        else:\n",
    "            republican_seats += state_electoral_votes\n",
    "            \n",
    "    elif position == 'split_called':\n",
    "        democrat_seats += seats_dem\n",
    "        republican_seats += seats_rep\n",
    "        # If there are remaining electoral votes, add to battleground\n",
    "        remaining_votes = state_electoral_votes - (seats_dem + seats_rep)\n",
    "        if remaining_votes > 0:\n",
    "            battleground_seats += remaining_votes\n",
    "            \n",
    "    else:  # battleground\n",
    "        battleground_seats += state_electoral_votes\n",
    "\n",
    "print(\"\\nFinal totals:\")\n",
    "print(f\"Democrat: {democrat_seats}\")\n",
    "print(f\"Republican: {republican_seats}\")\n",
    "print(f\"Battleground: {battleground_seats}\")\n",
    "print(f\"Total: {democrat_seats + republican_seats + battleground_seats}\")\n",
    "\n",
    "# Create widget DataFrame and save\n",
    "widget_df = pd.DataFrame({\n",
    "    'democrat': [int(democrat_seats)],\n",
    "    'republican': [int(republican_seats)],\n",
    "    'battleground': [int(battleground_seats)],\n",
    "    'lean_harris': [0],  # Added to maintain compatible format\n",
    "    'lean_trump': [0]    # Added to maintain compatible format\n",
    "})\n",
    "\n",
    "widget_df.to_csv(\"dpa_widget.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51c46963-66fa-45a2-a126-57fd8bdc341c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dpa_michigan.csv\n",
      "Updated dpa_wisconsin.csv\n",
      "Updated dpa_pennsylvania.csv\n",
      "Updated dpa_nevada.csv\n",
      "Updated dpa_arizona.csv\n",
      "Updated dpa_north_carolina.csv\n",
      "Updated dpa_georgia.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c8/bvk5bjs15mzg5h8m_jcbywx40000gn/T/ipykernel_83406/2288087970.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n",
      "/var/folders/c8/bvk5bjs15mzg5h8m_jcbywx40000gn/T/ipykernel_83406/2288087970.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n",
      "/var/folders/c8/bvk5bjs15mzg5h8m_jcbywx40000gn/T/ipykernel_83406/2288087970.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n",
      "/var/folders/c8/bvk5bjs15mzg5h8m_jcbywx40000gn/T/ipykernel_83406/2288087970.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n",
      "/var/folders/c8/bvk5bjs15mzg5h8m_jcbywx40000gn/T/ipykernel_83406/2288087970.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n",
      "/var/folders/c8/bvk5bjs15mzg5h8m_jcbywx40000gn/T/ipykernel_83406/2288087970.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n",
      "/var/folders/c8/bvk5bjs15mzg5h8m_jcbywx40000gn/T/ipykernel_83406/2288087970.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# swing_states = ['michigan', 'wisconsin', 'pennsylvania', 'nevada', 'arizona', 'north_carolina', 'georgia']\n",
    "\n",
    "# def update_state_data(state, results_row):\n",
    "#     csv_name = f\"dpa_{state.lower().replace(' ', '_')}.csv\"\n",
    "#     df = pd.read_csv(csv_name, parse_dates=['date'])\n",
    "    \n",
    "#     # Convert scores to float for proper comparison\n",
    "#     trump_score = float(results_row['trump_score']) if results_row['trump_score'] != '' else 0\n",
    "#     harris_score = float(results_row['harris_score']) if results_row['harris_score'] != '' else 0\n",
    "    \n",
    "#     new_row = pd.DataFrame({\n",
    "#         'date': [datetime.now()],\n",
    "#         'trump_score': [results_row['trump_score']],\n",
    "#         'harris_score': [results_row['harris_score']],\n",
    "#         'candidate_lead': ['harris' if harris_score > trump_score else 'trump' if trump_score > harris_score else ''],\n",
    "#         'position': [results_row['position']]\n",
    "#     })\n",
    "    \n",
    "#     df = pd.concat([df, new_row], ignore_index=True)\n",
    "#     df.to_csv(csv_name, index=False)\n",
    "#     print(f\"Updated {csv_name}\")\n",
    "\n",
    "# def normalize_state_name(name):\n",
    "#     return name.lower().replace(' ', '_')\n",
    "\n",
    "# def update_swing_state_data(results_df):\n",
    "#     results_df['normalized_state'] = results_df['state'].apply(normalize_state_name)\n",
    "    \n",
    "#     for state in swing_states:\n",
    "#         csv_name = f\"dpa_{state.lower().replace(' ', '_')}.csv\"\n",
    "        \n",
    "#         # Check the latest position in the current CSV\n",
    "#         current_df = pd.read_csv(csv_name)\n",
    "#         if not current_df.empty and current_df['position'].iloc[-1] in ['democrat', 'republican']:\n",
    "#             print(f\"Skipping {state} as it's already decided ({current_df['position'].iloc[-1]})\")\n",
    "#             continue\n",
    "        \n",
    "#         # Find the corresponding row in results_df\n",
    "#         state_data = results_df[results_df['normalized_state'] == normalize_state_name(state)]\n",
    "        \n",
    "#         if not state_data.empty:\n",
    "#             update_state_data(state, state_data.iloc[0])\n",
    "#         else:\n",
    "#             print(f\"No data found for {state} in results_df\")\n",
    "\n",
    "# update_swing_state_data(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dea63af-5d3e-4f4a-985a-16d3943ae9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset and created empty CSV file: dpa_michigan.csv\n",
      "Reset and created empty CSV file: dpa_wisconsin.csv\n",
      "Reset and created empty CSV file: dpa_pennsylvania.csv\n",
      "Reset and created empty CSV file: dpa_nevada.csv\n",
      "Reset and created empty CSV file: dpa_arizona.csv\n",
      "Reset and created empty CSV file: dpa_north_carolina.csv\n",
      "Reset and created empty CSV file: dpa_georgia.csv\n"
     ]
    }
   ],
   "source": [
    "# erase and re-create all csvs\n",
    "# import os\n",
    "# columns = ['date', 'trump_score', 'harris_score', 'candidate_lead', 'position']\n",
    "\n",
    "# # Function to reset CSV files\n",
    "# def reset_csv_files():\n",
    "#     for state in swing_states:\n",
    "#         filename = f\"dpa_{state.lower().replace(' ', '_')}.csv\"\n",
    "#         # Remove existing file if it exists\n",
    "#         if os.path.exists(filename):\n",
    "#             os.remove(filename)\n",
    "#         # Create new empty CSV file\n",
    "#         df = pd.DataFrame(columns=columns)\n",
    "#         df.to_csv(filename, index=False)\n",
    "#         print(f\"Reset and created empty CSV file: {filename}\")\n",
    "\n",
    "# reset_csv_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d2b9a7-fcbe-43c0-b0d0-99b8cd4c989b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
